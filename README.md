# ğŸš€ End-to-End ELT Data Engineering Project using dbt + PostgreSQL

[![dbt](https://img.shields.io/badge/dbt-1.10+-FF694B?logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-336791?logo=postgresql)](https://www.postgresql.org/)
[![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](#)

This project demonstrates an **end-to-end ELT (Extract, Load, Transform)** workflow using **dbt (Data Build Tool)** and **PostgreSQL**.  
It simulates a real-world data pipeline following the **Bronze â†’ Silver â†’ Gold** architecture to transform raw data into business-ready insights.

---

## ğŸ¦¯ Project Overview

The pipeline ingests raw data into **PostgreSQL**, applies transformations using **dbt**, and produces analytics models in three layers:

- ğŸ”¤ **Bronze Layer:** Raw data ingestion & staging  
- âšª **Silver Layer:** Data cleaning, validation, standardization  
- ğŸŸ¡ **Gold Layer:** Aggregations, business KPIs, and analytics models  

Each layer is materialized in its respective PostgreSQL schema.

---

## ğŸ— Folder Structure

```
DataEngineering_demo_with_dbt/
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Bronze/
â”‚   â”‚   â”œâ”€â”€ Silver/
â”‚   â”‚   â”œâ”€â”€ Gold/
â”‚   â”œâ”€â”€ snapshots/
â”‚   â”œâ”€â”€ macros/
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ dev_database_setup.sql
â”‚   â””â”€â”€ prod_database_setup.sql
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§± Architecture Diagram

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Source Data â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         ğŸŸ¤ Bronze Layer
        (Raw â†’ Staged)
               â”‚
               â–¼
         âšª Silver Layer
     (Cleaned â†’ Validated)
               â”‚
               â–¼
         ğŸŸ¡ Gold Layer
   (Aggregated â†’ Analytics)
```

---

## âš™ï¸ Setup Instructions

### ğŸ§© Step 1 â€” Create PostgreSQL Databases
Inside the `server/` folder, youâ€™ll find:
- `dev_database_setup.sql` â†’ Creates **ETL_dev**
- `prod_database_setup.sql` â†’ Creates **ETL_prod**

Run them in **pgAdmin** or **psql**:

```bash
\i 'path_to_project/server/dev_database_setup.sql'
\i 'path_to_project/server/prod_database_setup.sql'
```

These scripts create all schemas (`raw`, `geo`, `hr`, `inventory`, etc.) and sample data.

---

### ğŸ’» Step 2 â€” Set Up Virtual Environment

```bash
cd etl
python -m venv .venv
.venv\Scripts\activate        # On Windows
# or
source .venv/bin/activate     # On Mac/Linux
```

Then install dependencies:
```bash
pip install -r requirements.txt
```

---

### ğŸ§° Step 3 â€” Configure dbt Profiles

Create a file named **`profiles.yml`** (in your `etl/` folder or global dbt folder):

```yaml
etl:
  outputs:
    dev:
      database: ETL_dev
      host: localhost
      user: postgres
      pass: your_password
      port: 5432
      schema: default
      threads: 1
      type: postgres

    prod:
      database: ETL_prod
      host: localhost
      user: postgres
      pass: your_password
      port: 5432
      schema: default
      threads: 1
      type: postgres

  target: dev
```

---

### ğŸ§© Step 4 â€” Modify `source.yml` and Snapshots for Development

During **development**, dbt needs explicit database reference.  
Ensure:
```yaml
database: "{{ target.database }}"
```
is included in your `source.yml` and `snapshot` configs.

Then run:
```bash
dbt debug
dbt parse
dbt build
```

âœ… This will build and test all models in the **dev** environment.

---

### ğŸ§ª Step 5 â€” Validate Tests

Run all tests to confirm data quality:
```bash
dbt test
```

---

### ğŸš€ Step 6 â€” Deploy to Production

After successful development:

- Remove the `database:` field from your `source.yml` and snapshots.  
- Set your target to **prod** in `profiles.yml`:
  ```yaml
  target: prod
  ```

Then deploy:
```bash
dbt build --target prod
```

âœ… This runs all models (Bronze â†’ Silver â†’ Gold), snapshots, and tests on the production database.

---

### ğŸ“Š Step 7 â€” View Documentation

Generate and view dbt docs:
```bash
dbt docs generate
dbt docs serve
```
Open [http://localhost:8080](http://localhost:8080) to explore lineage graphs and model details.

---

## ğŸ§  Key dbt Commands Reference

| Command | Purpose |
|----------|----------|
| `dbt debug` | Validate connection & setup |
| `dbt parse` | Validate structure |
| `dbt run` | Run models only |
| `dbt test` | Run all data tests |
| `dbt snapshot` | Apply snapshots |
| `dbt build` | Run models + tests + snapshots |
| `dbt build --target prod` | Deploy to production |
| `dbt docs serve` | Serve docs locally |

---

## ğŸ” Security Note

Your `profiles.yml` contains credentials â€” **never commit it**.  
- Add it to `.gitignore`  
- Keep it locally only  
- If accidentally committed, remove and rotate credentials immediately  

---

## ğŸ§© Quick Summary

```bash
# Create Databases
psql -U postgres -f server/dev_database_setup.sql
psql -U postgres -f server/prod_database_setup.sql

# Setup Environment
cd etl
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# Develop in Dev
dbt build

# Deploy to Prod
dbt build --target prod
```

---

## ğŸ‘¨â€ğŸ’» Author

**Subhajit Nath**  
ğŸ’¼ Data Engineer | Building reliable data pipelines with dbt  ğŸ“Š  PostgreSQL  ğŸ’»  SQL  
ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/subajitnath)

---

## ğŸŒŸ If you found this useful
Give this repository a â­ on GitHub â€” it helps others discover it and supports continued learning!

---

### ğŸ Happy Building & Transforming Data with dbt!

